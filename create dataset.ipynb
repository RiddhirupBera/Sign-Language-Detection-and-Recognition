{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e3c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Code for Enter key: 13\n",
    "# Code for Nothing: 255\n",
    "# Code for Escape: 27\n",
    "\n",
    "import winsound\n",
    "frequency = 300  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "\n",
    "background = None\n",
    "alpha = 0.5 \n",
    "'''A lower value for this variable means \n",
    "running average will be performed over a larger amount of \n",
    "previous frames and vice-versa.'''\n",
    "\n",
    "ROI_top = 100\n",
    "ROI_bottom = 300\n",
    "ROI_right = 150\n",
    "ROI_left = 350\n",
    "ROI = {'top':100,'bottom':300,'right':150,'left':350}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30986bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_background(frame, alpha):\n",
    "\n",
    "    global background\n",
    "    \n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "    \n",
    "    '''The objective is to detect active objects from the difference obtained from \n",
    "    the reference frame and the current frame (background). We keep feeding each frame to the accumulateWeighted() function,\n",
    "    and the function keeps finding the averages of all frames. '''\n",
    "    \n",
    "    cv2.accumulateWeighted(frame, background, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b569d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hand(frame, threshold=25):\n",
    "    global background\n",
    "    \n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frame) #absolute difference between hand frame and background frame\n",
    "\n",
    "    _ , thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY) #if pixel value >=255, 1 else 0 (Binary thresholding)\n",
    "\n",
    "    # detects change in the image color and marks it as contour. Detection of hand before the background\n",
    "    contours, hierarchy = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "    # hierarchy: contains information about image topology; number of elements equal to number of contours\n",
    "\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        \n",
    "        hand_segment_max_cont = max(contours, key=cv2.contourArea) #sorts by contour area and finds contour with maximum area\n",
    "        \n",
    "        return (thresholded, hand_segment_max_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcec17c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 49\n",
      "breaking loop\n"
     ]
    }
   ],
   "source": [
    "f = True\n",
    "element = 0\n",
    "cam = cv2.VideoCapture(0)\n",
    "while f:\n",
    "    \n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # flipping the frame to prevent inverted image of captured frame...\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    cv2.putText(frame_copy, \"Enter next choice of character\", (0, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "    cv2.putText(frame_copy, \"Press Escape to exit\", (0, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "    cv2.imshow(\"Sign Language Image Data Collector\", frame_copy)\n",
    "    num_frames = 0\n",
    "    ele0 = cv2.waitKey(1) & 0xFF\n",
    "    if ele0==27: #break loop for escape\n",
    "        print(\"breaking loop\")\n",
    "        break\n",
    "    element = chr(ele0)\n",
    "    #element = 'A'\n",
    "    num_imgs_taken = 0\n",
    "    print(chr(ele0),ele0) if ele0!=255 else print(end=\"\")\n",
    "    while ele0!=255 and ele0!=13:\n",
    "        ret, frame = cam.read()\n",
    "\n",
    "        # flipping the frame to prevent inverted image of captured frame...\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        frame_copy = frame.copy()\n",
    "\n",
    "        roi = frame[ROI['top']:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "        gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "\n",
    "        if num_frames < 60:\n",
    "            calc_background(gray_frame, alpha)\n",
    "            cv2.putText(frame_copy, \"Reading background data...\", (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "            \n",
    "        #Time to configure the hand specifically into the ROI...\n",
    "        elif num_frames <= 300: \n",
    "\n",
    "            hand = detect_hand(gray_frame)\n",
    "            \n",
    "            cv2.putText(frame_copy, \"Make gesture for '\"+str(element)+\"'\", (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "            # Checking if hand is actually detected by counting number of contours detected...\n",
    "            if hand is not None:\n",
    "                \n",
    "                thresholded, hand_segment = hand\n",
    "\n",
    "                # Draw contours around hand segment\n",
    "                cv2.drawContours(frame_copy, [hand_segment + (ROI_right, ROI['top'])], -1, (255, 0, 0),1)\n",
    "                \n",
    "                cv2.putText(frame_copy, str(num_frames)+\" for \" + str(element), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "                # Also display the thresholded image\n",
    "                cv2.imshow(\"Thresholded Hand Image\", thresholded)\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            # Segmenting the hand region...\n",
    "            hand = detect_hand(gray_frame)\n",
    "            # Checking if we are able to detect the hand...\n",
    "            if hand is not None:\n",
    "                \n",
    "                # unpack the thresholded img and the max_contour...\n",
    "                thresholded, hand_segment = hand\n",
    "\n",
    "                # Drawing contours around hand segment\n",
    "                cv2.drawContours(frame_copy, [hand_segment + (ROI_right, ROI['top'])], -1, (255, 0, 0),1)\n",
    "                \n",
    "                \n",
    "                cv2.putText(frame_copy, str(num_imgs_taken) + 'images for' + str(element), (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                \n",
    "                # Displaying the thresholded image\n",
    "                cv2.imshow(\"Thresholded Hand Image\", thresholded)\n",
    "                if num_imgs_taken <= 500:\n",
    "                    cv2.putText(frame_copy, 'Collected '+str(num_imgs_taken)+' training images for' + str(element), (0, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "#                     Path(\"gesture/train/\"+str(element)+\"/\").mkdir(parents=True, exist_ok=True)\n",
    "#                     printed = cv2.imwrite(r\"data2/train/\"+str(element)+\"/\"+str(num_imgs_taken) + '.jpg', thresholded)\n",
    "#                     print(printed,\" img: \",num_imgs_taken ) if not printed else print(end=\"\")\n",
    "#                     pass\n",
    "                elif num_imgs_taken<=600:\n",
    "                    cv2.putText(frame_copy, 'Collected '+str(num_imgs_taken)+' testing images for' + str(element), (0, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "#                     Path(\"gesture/test/\"+str(element)+\"/\").mkdir(parents=True, exist_ok=True)\n",
    "#                     printed = cv2.imwrite(r\"data2/test/\"+str(element)+\"/\"+str(num_imgs_taken) + '.jpg', thresholded)\n",
    "#                     print(printed,\" img: \",num_imgs_taken ) if not printed else print(end=\"\")\n",
    "#                     pass\n",
    "                else:\n",
    "                    break\n",
    "                num_imgs_taken+=1\n",
    "            else:\n",
    "                cv2.putText(frame_copy, 'No hand detected...', (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "        # Drawing ROI on frame copy\n",
    "        cv2.rectangle(frame_copy, (ROI_left, ROI['top']), (ROI_right, ROI_bottom), (255,128,0), 3)\n",
    "        \n",
    "        cv2.putText(frame_copy, \"CSE4020 J Component - Sign Language Detection & Recognition\", (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "        \n",
    "        # increment the number of frames for tracking\n",
    "        num_frames += 1\n",
    "\n",
    "        # Display the frame with segmented hand\n",
    "        cv2.imshow(\"Sign Language Image Data Collector\", frame_copy)\n",
    "\n",
    "        # Closing windows with Esc key...(any other key with ord can be used too.)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "    \n",
    "\n",
    "    #f = False\n",
    "# Releasing camera & destroying all the windows...\n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "157e7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179101b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
